{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "o1QPDk8i0GKa"
      },
      "outputs": [],
      "source": [
        "## IMPORT NECESSARY LIBRARIES\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## LOADING THE DATASET\n",
        "iris = load_iris()\n"
      ],
      "metadata": {
        "id": "xyoKVff10pK5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## SEPARATING THE DATASET INTO FEATURES AND TARGET VALUES\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwYojEwk0pHp",
        "outputId": "2fa3039f-5479-433a-feb6-cb31b4050a4b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 4)\n",
            "(150,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##  PREPROCESSINF THE DATA BY SCALING THE FEATURES\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4QAGjwH0pFh",
        "outputId": "00a91459-74c7-481c-d452-ec91ad102bed"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-9.00681170e-01,  1.01900435e+00, -1.34022653e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.14301691e+00, -1.31979479e-01, -1.34022653e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.38535265e+00,  3.28414053e-01, -1.39706395e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.50652052e+00,  9.82172869e-02, -1.28338910e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.02184904e+00,  1.24920112e+00, -1.34022653e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-5.37177559e-01,  1.93979142e+00, -1.16971425e+00,\n",
              "        -1.05217993e+00],\n",
              "       [-1.50652052e+00,  7.88807586e-01, -1.34022653e+00,\n",
              "        -1.18381211e+00],\n",
              "       [-1.02184904e+00,  7.88807586e-01, -1.28338910e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.74885626e+00, -3.62176246e-01, -1.34022653e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.14301691e+00,  9.82172869e-02, -1.28338910e+00,\n",
              "        -1.44707648e+00],\n",
              "       [-5.37177559e-01,  1.47939788e+00, -1.28338910e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.26418478e+00,  7.88807586e-01, -1.22655167e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.26418478e+00, -1.31979479e-01, -1.34022653e+00,\n",
              "        -1.44707648e+00],\n",
              "       [-1.87002413e+00, -1.31979479e-01, -1.51073881e+00,\n",
              "        -1.44707648e+00],\n",
              "       [-5.25060772e-02,  2.16998818e+00, -1.45390138e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.73673948e-01,  3.09077525e+00, -1.28338910e+00,\n",
              "        -1.05217993e+00],\n",
              "       [-5.37177559e-01,  1.93979142e+00, -1.39706395e+00,\n",
              "        -1.05217993e+00],\n",
              "       [-9.00681170e-01,  1.01900435e+00, -1.34022653e+00,\n",
              "        -1.18381211e+00],\n",
              "       [-1.73673948e-01,  1.70959465e+00, -1.16971425e+00,\n",
              "        -1.18381211e+00],\n",
              "       [-9.00681170e-01,  1.70959465e+00, -1.28338910e+00,\n",
              "        -1.18381211e+00],\n",
              "       [-5.37177559e-01,  7.88807586e-01, -1.16971425e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-9.00681170e-01,  1.47939788e+00, -1.28338910e+00,\n",
              "        -1.05217993e+00],\n",
              "       [-1.50652052e+00,  1.24920112e+00, -1.56757623e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-9.00681170e-01,  5.58610819e-01, -1.16971425e+00,\n",
              "        -9.20547742e-01],\n",
              "       [-1.26418478e+00,  7.88807586e-01, -1.05603939e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.02184904e+00, -1.31979479e-01, -1.22655167e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.02184904e+00,  7.88807586e-01, -1.22655167e+00,\n",
              "        -1.05217993e+00],\n",
              "       [-7.79513300e-01,  1.01900435e+00, -1.28338910e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-7.79513300e-01,  7.88807586e-01, -1.34022653e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.38535265e+00,  3.28414053e-01, -1.22655167e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.26418478e+00,  9.82172869e-02, -1.22655167e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-5.37177559e-01,  7.88807586e-01, -1.28338910e+00,\n",
              "        -1.05217993e+00],\n",
              "       [-7.79513300e-01,  2.40018495e+00, -1.28338910e+00,\n",
              "        -1.44707648e+00],\n",
              "       [-4.16009689e-01,  2.63038172e+00, -1.34022653e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.14301691e+00,  9.82172869e-02, -1.28338910e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.02184904e+00,  3.28414053e-01, -1.45390138e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-4.16009689e-01,  1.01900435e+00, -1.39706395e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.14301691e+00,  1.24920112e+00, -1.34022653e+00,\n",
              "        -1.44707648e+00],\n",
              "       [-1.74885626e+00, -1.31979479e-01, -1.39706395e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-9.00681170e-01,  7.88807586e-01, -1.28338910e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.02184904e+00,  1.01900435e+00, -1.39706395e+00,\n",
              "        -1.18381211e+00],\n",
              "       [-1.62768839e+00, -1.74335684e+00, -1.39706395e+00,\n",
              "        -1.18381211e+00],\n",
              "       [-1.74885626e+00,  3.28414053e-01, -1.39706395e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.02184904e+00,  1.01900435e+00, -1.22655167e+00,\n",
              "        -7.88915558e-01],\n",
              "       [-9.00681170e-01,  1.70959465e+00, -1.05603939e+00,\n",
              "        -1.05217993e+00],\n",
              "       [-1.26418478e+00, -1.31979479e-01, -1.34022653e+00,\n",
              "        -1.18381211e+00],\n",
              "       [-9.00681170e-01,  1.70959465e+00, -1.22655167e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.50652052e+00,  3.28414053e-01, -1.34022653e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-6.58345429e-01,  1.47939788e+00, -1.28338910e+00,\n",
              "        -1.31544430e+00],\n",
              "       [-1.02184904e+00,  5.58610819e-01, -1.34022653e+00,\n",
              "        -1.31544430e+00],\n",
              "       [ 1.40150837e+00,  3.28414053e-01,  5.35408562e-01,\n",
              "         2.64141916e-01],\n",
              "       [ 6.74501145e-01,  3.28414053e-01,  4.21733708e-01,\n",
              "         3.95774101e-01],\n",
              "       [ 1.28034050e+00,  9.82172869e-02,  6.49083415e-01,\n",
              "         3.95774101e-01],\n",
              "       [-4.16009689e-01, -1.74335684e+00,  1.37546573e-01,\n",
              "         1.32509732e-01],\n",
              "       [ 7.95669016e-01, -5.92373012e-01,  4.78571135e-01,\n",
              "         3.95774101e-01],\n",
              "       [-1.73673948e-01, -5.92373012e-01,  4.21733708e-01,\n",
              "         1.32509732e-01],\n",
              "       [ 5.53333275e-01,  5.58610819e-01,  5.35408562e-01,\n",
              "         5.27406285e-01],\n",
              "       [-1.14301691e+00, -1.51316008e+00, -2.60315415e-01,\n",
              "        -2.62386821e-01],\n",
              "       [ 9.16836886e-01, -3.62176246e-01,  4.78571135e-01,\n",
              "         1.32509732e-01],\n",
              "       [-7.79513300e-01, -8.22569778e-01,  8.07091462e-02,\n",
              "         2.64141916e-01],\n",
              "       [-1.02184904e+00, -2.43394714e+00, -1.46640561e-01,\n",
              "        -2.62386821e-01],\n",
              "       [ 6.86617933e-02, -1.31979479e-01,  2.51221427e-01,\n",
              "         3.95774101e-01],\n",
              "       [ 1.89829664e-01, -1.97355361e+00,  1.37546573e-01,\n",
              "        -2.62386821e-01],\n",
              "       [ 3.10997534e-01, -3.62176246e-01,  5.35408562e-01,\n",
              "         2.64141916e-01],\n",
              "       [-2.94841818e-01, -3.62176246e-01, -8.98031345e-02,\n",
              "         1.32509732e-01],\n",
              "       [ 1.03800476e+00,  9.82172869e-02,  3.64896281e-01,\n",
              "         2.64141916e-01],\n",
              "       [-2.94841818e-01, -1.31979479e-01,  4.21733708e-01,\n",
              "         3.95774101e-01],\n",
              "       [-5.25060772e-02, -8.22569778e-01,  1.94384000e-01,\n",
              "        -2.62386821e-01],\n",
              "       [ 4.32165405e-01, -1.97355361e+00,  4.21733708e-01,\n",
              "         3.95774101e-01],\n",
              "       [-2.94841818e-01, -1.28296331e+00,  8.07091462e-02,\n",
              "        -1.30754636e-01],\n",
              "       [ 6.86617933e-02,  3.28414053e-01,  5.92245988e-01,\n",
              "         7.90670654e-01],\n",
              "       [ 3.10997534e-01, -5.92373012e-01,  1.37546573e-01,\n",
              "         1.32509732e-01],\n",
              "       [ 5.53333275e-01, -1.28296331e+00,  6.49083415e-01,\n",
              "         3.95774101e-01],\n",
              "       [ 3.10997534e-01, -5.92373012e-01,  5.35408562e-01,\n",
              "         8.77547895e-04],\n",
              "       [ 6.74501145e-01, -3.62176246e-01,  3.08058854e-01,\n",
              "         1.32509732e-01],\n",
              "       [ 9.16836886e-01, -1.31979479e-01,  3.64896281e-01,\n",
              "         2.64141916e-01],\n",
              "       [ 1.15917263e+00, -5.92373012e-01,  5.92245988e-01,\n",
              "         2.64141916e-01],\n",
              "       [ 1.03800476e+00, -1.31979479e-01,  7.05920842e-01,\n",
              "         6.59038469e-01],\n",
              "       [ 1.89829664e-01, -3.62176246e-01,  4.21733708e-01,\n",
              "         3.95774101e-01],\n",
              "       [-1.73673948e-01, -1.05276654e+00, -1.46640561e-01,\n",
              "        -2.62386821e-01],\n",
              "       [-4.16009689e-01, -1.51316008e+00,  2.38717193e-02,\n",
              "        -1.30754636e-01],\n",
              "       [-4.16009689e-01, -1.51316008e+00, -3.29657076e-02,\n",
              "        -2.62386821e-01],\n",
              "       [-5.25060772e-02, -8.22569778e-01,  8.07091462e-02,\n",
              "         8.77547895e-04],\n",
              "       [ 1.89829664e-01, -8.22569778e-01,  7.62758269e-01,\n",
              "         5.27406285e-01],\n",
              "       [-5.37177559e-01, -1.31979479e-01,  4.21733708e-01,\n",
              "         3.95774101e-01],\n",
              "       [ 1.89829664e-01,  7.88807586e-01,  4.21733708e-01,\n",
              "         5.27406285e-01],\n",
              "       [ 1.03800476e+00,  9.82172869e-02,  5.35408562e-01,\n",
              "         3.95774101e-01],\n",
              "       [ 5.53333275e-01, -1.74335684e+00,  3.64896281e-01,\n",
              "         1.32509732e-01],\n",
              "       [-2.94841818e-01, -1.31979479e-01,  1.94384000e-01,\n",
              "         1.32509732e-01],\n",
              "       [-4.16009689e-01, -1.28296331e+00,  1.37546573e-01,\n",
              "         1.32509732e-01],\n",
              "       [-4.16009689e-01, -1.05276654e+00,  3.64896281e-01,\n",
              "         8.77547895e-04],\n",
              "       [ 3.10997534e-01, -1.31979479e-01,  4.78571135e-01,\n",
              "         2.64141916e-01],\n",
              "       [-5.25060772e-02, -1.05276654e+00,  1.37546573e-01,\n",
              "         8.77547895e-04],\n",
              "       [-1.02184904e+00, -1.74335684e+00, -2.60315415e-01,\n",
              "        -2.62386821e-01],\n",
              "       [-2.94841818e-01, -8.22569778e-01,  2.51221427e-01,\n",
              "         1.32509732e-01],\n",
              "       [-1.73673948e-01, -1.31979479e-01,  2.51221427e-01,\n",
              "         8.77547895e-04],\n",
              "       [-1.73673948e-01, -3.62176246e-01,  2.51221427e-01,\n",
              "         1.32509732e-01],\n",
              "       [ 4.32165405e-01, -3.62176246e-01,  3.08058854e-01,\n",
              "         1.32509732e-01],\n",
              "       [-9.00681170e-01, -1.28296331e+00, -4.30827696e-01,\n",
              "        -1.30754636e-01],\n",
              "       [-1.73673948e-01, -5.92373012e-01,  1.94384000e-01,\n",
              "         1.32509732e-01],\n",
              "       [ 5.53333275e-01,  5.58610819e-01,  1.27429511e+00,\n",
              "         1.71209594e+00],\n",
              "       [-5.25060772e-02, -8.22569778e-01,  7.62758269e-01,\n",
              "         9.22302838e-01],\n",
              "       [ 1.52267624e+00, -1.31979479e-01,  1.21745768e+00,\n",
              "         1.18556721e+00],\n",
              "       [ 5.53333275e-01, -3.62176246e-01,  1.04694540e+00,\n",
              "         7.90670654e-01],\n",
              "       [ 7.95669016e-01, -1.31979479e-01,  1.16062026e+00,\n",
              "         1.31719939e+00],\n",
              "       [ 2.12851559e+00, -1.31979479e-01,  1.61531967e+00,\n",
              "         1.18556721e+00],\n",
              "       [-1.14301691e+00, -1.28296331e+00,  4.21733708e-01,\n",
              "         6.59038469e-01],\n",
              "       [ 1.76501198e+00, -3.62176246e-01,  1.44480739e+00,\n",
              "         7.90670654e-01],\n",
              "       [ 1.03800476e+00, -1.28296331e+00,  1.16062026e+00,\n",
              "         7.90670654e-01],\n",
              "       [ 1.64384411e+00,  1.24920112e+00,  1.33113254e+00,\n",
              "         1.71209594e+00],\n",
              "       [ 7.95669016e-01,  3.28414053e-01,  7.62758269e-01,\n",
              "         1.05393502e+00],\n",
              "       [ 6.74501145e-01, -8.22569778e-01,  8.76433123e-01,\n",
              "         9.22302838e-01],\n",
              "       [ 1.15917263e+00, -1.31979479e-01,  9.90107977e-01,\n",
              "         1.18556721e+00],\n",
              "       [-1.73673948e-01, -1.28296331e+00,  7.05920842e-01,\n",
              "         1.05393502e+00],\n",
              "       [-5.25060772e-02, -5.92373012e-01,  7.62758269e-01,\n",
              "         1.58046376e+00],\n",
              "       [ 6.74501145e-01,  3.28414053e-01,  8.76433123e-01,\n",
              "         1.44883158e+00],\n",
              "       [ 7.95669016e-01, -1.31979479e-01,  9.90107977e-01,\n",
              "         7.90670654e-01],\n",
              "       [ 2.24968346e+00,  1.70959465e+00,  1.67215710e+00,\n",
              "         1.31719939e+00],\n",
              "       [ 2.24968346e+00, -1.05276654e+00,  1.78583195e+00,\n",
              "         1.44883158e+00],\n",
              "       [ 1.89829664e-01, -1.97355361e+00,  7.05920842e-01,\n",
              "         3.95774101e-01],\n",
              "       [ 1.28034050e+00,  3.28414053e-01,  1.10378283e+00,\n",
              "         1.44883158e+00],\n",
              "       [-2.94841818e-01, -5.92373012e-01,  6.49083415e-01,\n",
              "         1.05393502e+00],\n",
              "       [ 2.24968346e+00, -5.92373012e-01,  1.67215710e+00,\n",
              "         1.05393502e+00],\n",
              "       [ 5.53333275e-01, -8.22569778e-01,  6.49083415e-01,\n",
              "         7.90670654e-01],\n",
              "       [ 1.03800476e+00,  5.58610819e-01,  1.10378283e+00,\n",
              "         1.18556721e+00],\n",
              "       [ 1.64384411e+00,  3.28414053e-01,  1.27429511e+00,\n",
              "         7.90670654e-01],\n",
              "       [ 4.32165405e-01, -5.92373012e-01,  5.92245988e-01,\n",
              "         7.90670654e-01],\n",
              "       [ 3.10997534e-01, -1.31979479e-01,  6.49083415e-01,\n",
              "         7.90670654e-01],\n",
              "       [ 6.74501145e-01, -5.92373012e-01,  1.04694540e+00,\n",
              "         1.18556721e+00],\n",
              "       [ 1.64384411e+00, -1.31979479e-01,  1.16062026e+00,\n",
              "         5.27406285e-01],\n",
              "       [ 1.88617985e+00, -5.92373012e-01,  1.33113254e+00,\n",
              "         9.22302838e-01],\n",
              "       [ 2.49201920e+00,  1.70959465e+00,  1.50164482e+00,\n",
              "         1.05393502e+00],\n",
              "       [ 6.74501145e-01, -5.92373012e-01,  1.04694540e+00,\n",
              "         1.31719939e+00],\n",
              "       [ 5.53333275e-01, -5.92373012e-01,  7.62758269e-01,\n",
              "         3.95774101e-01],\n",
              "       [ 3.10997534e-01, -1.05276654e+00,  1.04694540e+00,\n",
              "         2.64141916e-01],\n",
              "       [ 2.24968346e+00, -1.31979479e-01,  1.33113254e+00,\n",
              "         1.44883158e+00],\n",
              "       [ 5.53333275e-01,  7.88807586e-01,  1.04694540e+00,\n",
              "         1.58046376e+00],\n",
              "       [ 6.74501145e-01,  9.82172869e-02,  9.90107977e-01,\n",
              "         7.90670654e-01],\n",
              "       [ 1.89829664e-01, -1.31979479e-01,  5.92245988e-01,\n",
              "         7.90670654e-01],\n",
              "       [ 1.28034050e+00,  9.82172869e-02,  9.33270550e-01,\n",
              "         1.18556721e+00],\n",
              "       [ 1.03800476e+00,  9.82172869e-02,  1.04694540e+00,\n",
              "         1.58046376e+00],\n",
              "       [ 1.28034050e+00,  9.82172869e-02,  7.62758269e-01,\n",
              "         1.44883158e+00],\n",
              "       [-5.25060772e-02, -8.22569778e-01,  7.62758269e-01,\n",
              "         9.22302838e-01],\n",
              "       [ 1.15917263e+00,  3.28414053e-01,  1.21745768e+00,\n",
              "         1.44883158e+00],\n",
              "       [ 1.03800476e+00,  5.58610819e-01,  1.10378283e+00,\n",
              "         1.71209594e+00],\n",
              "       [ 1.03800476e+00, -1.31979479e-01,  8.19595696e-01,\n",
              "         1.44883158e+00],\n",
              "       [ 5.53333275e-01, -1.28296331e+00,  7.05920842e-01,\n",
              "         9.22302838e-01],\n",
              "       [ 7.95669016e-01, -1.31979479e-01,  8.19595696e-01,\n",
              "         1.05393502e+00],\n",
              "       [ 4.32165405e-01,  7.88807586e-01,  9.33270550e-01,\n",
              "         1.44883158e+00],\n",
              "       [ 6.86617933e-02, -1.31979479e-01,  7.62758269e-01,\n",
              "         7.90670654e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ONE HOT ENCODING THE TARGET LABELS\n",
        "y_encoded = to_categorical(y, num_classes = 3)\n",
        "y_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNCRKyMY0pC4",
        "outputId": "afbc60f5-061f-4f7e-e0b9-042f5f16da85"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## SPLITTING THE DATASET INTO TRAINING AND TESTING SET\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZLnWTJf0pAb",
        "outputId": "a29ff4a2-81d9-4f42-b5bf-5ca38517e25a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120, 4)\n",
            "(120, 3)\n",
            "(30, 4)\n",
            "(30, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## BUILDING THE ANN MODEL\n",
        "model = Sequential()\n",
        "model.add(Dense(32, input_dim=4, activation='relu'))\n",
        "model.add(Dense(16, activation='elu'))\n",
        "model.add(Dense(8, activation= 'elu'))\n",
        "model.add(Dense(3, activation= 'softmax'))\n",
        "print(model.summary())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quGu-pYd0o7T",
        "outputId": "8e281b0a-95e8-41ae-f611-6ab640d9b428"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 32)                160       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 851 (3.32 KB)\n",
            "Trainable params: 851 (3.32 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## MODEL COMPILATION\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "vzCIEgxM0o4o"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TRAINING THE MODEL\n",
        "hist = model.fit(X_train, y_train, epochs = 100, batch_size = 10,  validation_data = (X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UqGpurF0o2X",
        "outputId": "409c6faa-796c-4546-a13e-f04b35cfcc0b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 17ms/step - loss: 1.1057 - accuracy: 0.3833 - val_loss: 0.9151 - val_accuracy: 0.6667\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8262 - accuracy: 0.6667 - val_loss: 0.6978 - val_accuracy: 0.8000\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6675 - accuracy: 0.7750 - val_loss: 0.5704 - val_accuracy: 0.8333\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5662 - accuracy: 0.8000 - val_loss: 0.4873 - val_accuracy: 0.8667\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.8000 - val_loss: 0.4247 - val_accuracy: 0.8667\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4468 - accuracy: 0.8083 - val_loss: 0.3760 - val_accuracy: 0.8667\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8333 - val_loss: 0.3375 - val_accuracy: 0.9000\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8333 - val_loss: 0.3056 - val_accuracy: 0.9000\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3470 - accuracy: 0.8500 - val_loss: 0.2783 - val_accuracy: 0.9000\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3224 - accuracy: 0.8833 - val_loss: 0.2569 - val_accuracy: 0.9000\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2997 - accuracy: 0.9083 - val_loss: 0.2349 - val_accuracy: 0.9667\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2795 - accuracy: 0.9167 - val_loss: 0.2184 - val_accuracy: 0.9333\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2622 - accuracy: 0.9250 - val_loss: 0.2008 - val_accuracy: 0.9667\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2442 - accuracy: 0.9417 - val_loss: 0.1862 - val_accuracy: 0.9667\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2261 - accuracy: 0.9583 - val_loss: 0.1727 - val_accuracy: 0.9667\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2117 - accuracy: 0.9583 - val_loss: 0.1577 - val_accuracy: 0.9667\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1984 - accuracy: 0.9583 - val_loss: 0.1475 - val_accuracy: 0.9667\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1853 - accuracy: 0.9583 - val_loss: 0.1377 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1726 - accuracy: 0.9583 - val_loss: 0.1239 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1614 - accuracy: 0.9583 - val_loss: 0.1148 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1507 - accuracy: 0.9583 - val_loss: 0.1104 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1427 - accuracy: 0.9583 - val_loss: 0.1015 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1343 - accuracy: 0.9583 - val_loss: 0.0946 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1326 - accuracy: 0.9583 - val_loss: 0.0924 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1206 - accuracy: 0.9583 - val_loss: 0.0817 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1173 - accuracy: 0.9500 - val_loss: 0.0766 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1095 - accuracy: 0.9583 - val_loss: 0.0740 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1065 - accuracy: 0.9667 - val_loss: 0.0717 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1041 - accuracy: 0.9583 - val_loss: 0.0654 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0979 - accuracy: 0.9667 - val_loss: 0.0615 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0939 - accuracy: 0.9750 - val_loss: 0.0579 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0907 - accuracy: 0.9667 - val_loss: 0.0549 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9583 - val_loss: 0.0508 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0861 - accuracy: 0.9667 - val_loss: 0.0559 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0837 - accuracy: 0.9667 - val_loss: 0.0475 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0809 - accuracy: 0.9667 - val_loss: 0.0432 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0793 - accuracy: 0.9750 - val_loss: 0.0432 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0763 - accuracy: 0.9750 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9667 - val_loss: 0.0422 - val_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9750 - val_loss: 0.0369 - val_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0757 - accuracy: 0.9667 - val_loss: 0.0446 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0747 - accuracy: 0.9750 - val_loss: 0.0363 - val_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.9750 - val_loss: 0.0352 - val_accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.9750 - val_loss: 0.0345 - val_accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.9833 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9833 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9750 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0647 - accuracy: 0.9667 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.9750 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0632 - accuracy: 0.9750 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0589 - accuracy: 0.9750 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 0.9833 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0596 - accuracy: 0.9833 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9833 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0586 - accuracy: 0.9833 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.9750 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 0.9833 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0580 - accuracy: 0.9833 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0544 - accuracy: 0.9833 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9833 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.9750 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0539 - accuracy: 0.9833 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0539 - accuracy: 0.9833 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9833 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.9833 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0527 - accuracy: 0.9750 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9917 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0510 - accuracy: 0.9750 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9833 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.9833 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0491 - accuracy: 0.9833 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0484 - accuracy: 0.9833 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0478 - accuracy: 0.9833 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.9833 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0527 - accuracy: 0.9750 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9917 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9833 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0468 - accuracy: 0.9833 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.9833 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0464 - accuracy: 0.9833 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0464 - accuracy: 0.9833 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0451 - accuracy: 0.9833 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0466 - accuracy: 0.9833 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0457 - accuracy: 0.9833 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0470 - accuracy: 0.9750 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0449 - accuracy: 0.9833 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0456 - accuracy: 0.9833 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.9750 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9917 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0459 - accuracy: 0.9833 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0445 - accuracy: 0.9917 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9833 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0444 - accuracy: 0.9917 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0435 - accuracy: 0.9917 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0418 - accuracy: 0.9833 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0420 - accuracy: 0.9833 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0425 - accuracy: 0.9833 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9833 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0418 - accuracy: 0.9833 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0419 - accuracy: 0.9833 - val_loss: 0.0128 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## MODEL PREDICTION FROM TEST DATA\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR1m2yFg0ozr",
        "outputId": "51d982cc-c428-4d2b-d495-37757be1da8e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 59ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## CONVERTING THE PREDICTION TO THEIR CLASS LABELS\n",
        "\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "predicted_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDK9bK2u0oxL",
        "outputId": "aa458bc4-219f-4433-9a2c-9b255c6d99bd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## COMPARING THE PREDICTED LABELS WITH THEIR TRUE LABELS\n",
        "true_classes = np.argmax(y_test, axis=1)\n",
        "print(\"Predictions:\", predicted_classes)\n",
        "print(\"True Labels:\", true_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3tdO-eB0ouv",
        "outputId": "e9baaca7-903c-4243-c93d-75bf5adc5a13"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
            "True Labels: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## MODEL EVALUATION\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgQ3geJs0osH",
        "outputId": "b7fd52ed-69b7-4a56-b133-858967c8d971"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0128 - accuracy: 1.0000\n",
            "Loss: 0.012766236439347267\n",
            "Test Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Wv_B5i90opG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dXBJ1DYS0oeu"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}